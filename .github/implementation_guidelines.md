# Pipeline Implementation Guidelines

This guideline outlines the agreed-upon criteria to be followed during the development of CIBERER
pipelines for genomic analyses.

## Inputs
- The preferred format for passing inputs to the pipeline will be a TSV file containing specific experiment information. This file will include paths to source files (e.g., *fastq* or *bam*), sample and/or individual identifiers, batch information, etc.
- Other necessary files for the pipeline (e.g., reference files) will be passed as arguments.
- Input validation will be implemented using the nf-validation plugin. This plugin will be applied to ensure that the arguments are the correct file type and to internally validate the TSV file.
- By default, pipelines will run from start to finish. However, pipelines will allow for the selection of steps to execute:
  - An argument (`--steps`) will be included to decide which steps to execute. This argument will take a comma-separated string of steps to perform. Exact matches between the steps included in the argument and the available options will be required.
  - Additionally, input TSV validation will allow starting the pipeline from different points, accommodating variations such as starting with a *fastq* or a *bam* file.
- Users will have the option to select which methods the pipeline should execute. By default, all available methods will be executed, and a parameter (`--methods`) will be provided to allow for the selection of specific methods. In cases where different methods are available at different stages (e.g., various alignment methods, variant calling methods, annotation methods), an argument will be defined for each group of methods (e.g., `--methods_alignment`, `--methods_variant_calling`, etc.). These arguments will require a comma-separated string of methods as input, ensuring an exact match between the specified methods and the available options.

## Outputs
- Outputs will adhere to a standardized format (e.g., VCF, BAM, BED, TSV). Due to the diversity of analyses, each working group will define the most suitable format for their pipeline.
- It will be considered the possibility of implementing a common annotation for both single nucleotide variants (SNVs) and structural variants (CNVs). 
- Final files from each step and the result of each method will be saved. The results folder structure will be based on the executed methods/steps. For instance, all files generated by VardictJava will be stored in the "vardictjava" folder. Files will be named with the individual's identifier. In intermediate files, where there might be multiple files for the same individual, additional identifiers such as the sample identifier will be included.
- Selection of returned files will be based on the nf-core template. Hence, a configuration file (`modules.config` in the `conf/` folder) specifying the files returned by each module will be added. Users can alter this configuration by changing the `publishDir` directive in the config file located in the working folder.
- Nextflow execution reports will be generated. Consideration will be given to including metadata in this file or including an additional file with metadata.

## Implementation
- Whenever possible, modules and workflows from nf-core will be imported.
    - If nf-core implementation does not fully meet pipeline needs, the nf-core file will be modified, adding changes as a patch using *nf-core tools patch*. This approach preserves code integrity and allows for future updates.
- Modules that are unavailable will be implemented locally. Priority will be given to using the nf-core template for general bioinformatics tools. In the future, inclusion of locally generated code into nf-core will be considered..
    - All locally implemented modules and subworkflows will have documentation following nf-core guidelines. Specifically, a `.yml` file containing at least inputs, outputs, and a description of what the module/subworkflow does will be added.
    - Locally implemented modules must have an associated container. [Biocontainers](https://biocontainers-edu.readthedocs.io/en/latest/biocontainers_registry.html) will be used whenever possible. If the tool is not available in Biocontainers, or for small scripts using only python or R, [DockerHub](https://hub.docker.com/) containers will be used. To manage these containers, a DockerFile with the necessary environment will be added to the repository, and container mounting will be automated with GitHub Actions.
- Tests will be included for all locally implemented modules, subworkflows, and the pipeline itself. In all cases, tests will be conducted using [nf-test](https://www.nf-test.com/). At a minimum, testing will ensure that the module/subworkflow/pipeline functions correctly when correct files and/or parameters are passed. Cases where inputs are evaluated will be tested by including erroneous inputs to verify proper evaluation.
- Several basic profiles (predefined combinations of parameters) will be implemented:
  - By default, nf-core template includes profiles for running the pipeline: docker, singularity, condaâ€¦
  - Profiles will be added to select reference files based on a reference genome. These profiles may include fasta, .fai, gene annotation, gene location, etc. By default, these profiles will point to URLs that automate the download of reference data. These genome-related profiles will be included as a separate file to facilitate user modification and inclusion of their own files locally.
  - A profile will be included to run the pipeline with test files. This dataset will be a minimal dataset that exemplifies pipeline functions and verifies that the pipeline runs correctly.
  - Consideration will be given to including an example of a configuration profile to run the pipeline on a server. This profile will be designed for users to adapt to their characteristics and not to be executed directly.

## Others
- Repositories will be hosted on GitHub.
- An institutional CIBERER user will be used to host the repositories.
- All repositories will be public.
